{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Transcript\n",
    "Hier wird die Audio per [Whisper](https://github.com/linto-ai/whisper-timestamped) in Text umgewandelt.\n",
    "das Transkript wird in result (als JSON) gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5173/5173 [00:58<00:00, 89.14frames/s]\n"
     ]
    }
   ],
   "source": [
    "import whisper_timestamped as whisper\n",
    "\n",
    "# convert video to audio: ffmpeg -i <infile> -ac 2 -f wav <outfile>\n",
    "file = \"test03.wav\"\n",
    "audio = whisper.load_audio(f\"../{file}\")\n",
    "model = whisper.load_model(\"large\", device=\"cpu\")\n",
    "result = whisper.transcribe(model, audio, language=\"de\", vad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def format_timestamp(seconds: float, always_include_hours: bool = False, decimal_marker: str = '.'):\n",
    "    assert seconds >= 0, \"non-negative timestamp expected\"\n",
    "    milliseconds = round(seconds * 1000.0)\n",
    "\n",
    "    hours = milliseconds // 3_600_000\n",
    "    milliseconds -= hours * 3_600_000\n",
    "\n",
    "    minutes = milliseconds // 60_000\n",
    "    milliseconds -= minutes * 60_000\n",
    "\n",
    "    seconds = milliseconds // 1_000\n",
    "    milliseconds -= seconds * 1_000\n",
    "\n",
    "    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
    "    return f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
    "\n",
    "str = \"\"\n",
    "for segment in result[\"segments\"]:\n",
    "    str +=  f\"{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])} \\n #{segment['text'].strip().replace('-->', '->')}\\n\\n\"\n",
    "\n",
    "#print(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personen identifizieren\n",
    "pyannote funktioniert irgendwie nicht so gut mit poetry, bzw. nicht zusammen mit den anderen Abhängigkeiten. Daher wurde es hier auch nicht weiter implementiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "pipeline.to(torch.device(\"cpu\"))\n",
    "diarization = pipeline(audio)\n",
    "\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "speaker = diarization.itertracks(yield_label=True)\n",
    "\n",
    "hf_model = pipeline(\"feature-extraction\", model=\"DataikuNLP/paraphrase-albert-small-v2\")\n",
    "kw_model = KeyBERT(model=hf_model)\n",
    "\n",
    "#idx = 0\n",
    "#offset = 2\n",
    "#for segment in result[\"segments\"]:\n",
    "#    if segment[\"start\"] - offset < speaker[idx][0].satrt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anfrage an TU BS KI Toolbox:\n",
    "Dient nur zum beschleunigen und Verbessern der LLM Anfragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def delete_chat(chat_id):\n",
    "    url = f'https://ki-toolbox.tu-braunschweig.de/api/v1/chat/{chat_id}'\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Authorization': 'Bearer f37f50c353a74644842e609e78b4df0c'  # Ihr Token hier\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.delete(url, headers=headers)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the response status code indicates an error\n",
    "        #print(\"Chat deleted successfully.\")\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred while deleting chat: {http_err}\")  # HTTP-Fehler behandeln\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred while deleting chat: {err}\")  # Andere Fehler behandeln\n",
    "\n",
    "\n",
    "def send_promt_to_ki(promt):\n",
    "    url = 'https://ki-toolbox.tu-braunschweig.de/api/v1/chat/send'\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Authorization': 'Bearer f37f50c353a74644842e609e78b4df0c',  # Ihr Token hier\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        \"thread\": None,\n",
    "        \"prompt\": promt,\n",
    "        \"model\": \"gpt-4o\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()  # Raises an HTTPError if the response status code indicates an error\n",
    "\n",
    "        raw_response = response.text\n",
    "        #print(\"Raw response text:\", raw_response)  # Ausgabe der Rohantwort\n",
    "\n",
    "        final_response = None\n",
    "        chat_id = None\n",
    "\n",
    "        # Verarbeiten Sie die Rohantwort zeilenweise\n",
    "        for line in raw_response.splitlines():\n",
    "            if not line.strip():  # Überspringen Sie leere Zeilen\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                obj = json.loads(line)  # Jede Zeile als JSON-Objekt laden\n",
    "                if obj['type'] == 'done':  # Suchen Sie nach dem 'done'-Objekt\n",
    "                    final_response = obj['response']\n",
    "                elif 'thread' in obj:  # Wenn ein Thread-Objekt vorhanden ist\n",
    "                    chat_id = obj['thread']['id']\n",
    "            except json.JSONDecodeError as json_err:\n",
    "                print(f\"JSON decode error for line: {line} - Error: {json_err}\")\n",
    "\n",
    "        if chat_id is not None:\n",
    "            delete_chat(chat_id)  # Chat löschen, wenn die Chat-ID vorhanden ist\n",
    "        else:\n",
    "            print(\"No chat ID available for deletion.\")\n",
    "            \n",
    "        return final_response, chat_id  # Gibt die endgültige Antwort und die Chat-ID zurück\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")  # HTTP-Fehler behandeln\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")  # Andere Fehler behandeln\n",
    "\n",
    "    return None, None  # Gibt None zurück, wenn ein Fehler aufgetreten ist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ist Beleidigung\n",
    "Nutze ein LLM, um zu jedem Segment zu prüfen, ob es sich um eine Beleidigung Handelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gut, weil die Situation sich gerade zuspitzt, fange ich an mit meiner Bodycam zu filmen. -> Nein\n",
      "Spitz dich denn hier zu, du Arschloch! -> Ja\n",
      "Sie hören doch, wie Sie mit mir reden. Sie können doch auch ganz vernünftig mit mir reden. -> Nein\n",
      "Nee, Sie wollen ja Papiere. -> Nein\n",
      "Ich sag's Ihnen, Sie wird in Ruhe. -> Nein\n",
      "Okay, also ich hab's Ihnen jetzt schon erklärt. Das ist eine ganz normale Personenkontrolle. -> Nein\n",
      "Ich brauch einmal Ihre Ausweise und danach dürfen Sie auch wieder gehen. -> Nein\n",
      "Die hab ich aber nicht dabei. -> Nein\n",
      "Ja, da kommen wir leider nicht weiter. Da kommen wir leider nicht weiter, weil ich muss den leider einsehen. -> Nein\n",
      "Okay? Also müssen Sie irgendwas mir bieten, womit Sie sich ausweisen können. -> Nein\n",
      "Ja, Datenschutz. -> Nein\n",
      "Sie Arschloch. -> Ja\n",
      "Wie reden Sie denn mit mir? Was soll denn das? -> Nein\n",
      "Ach, lassen Sie mich einfach in Ruhe, Fakio. -> Ja\n",
      "\n",
      "Fertig\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "for segment in result[\"segments\"]:\n",
    "  text = segment['text'].strip().replace('-->', '->')\n",
    "  promt = f\"Ist die folgende Aussage eine Beleidigung oder enthält diese eine? Beispiele für eine Beleidigung wären Arschloch, Pimmel, Fuck You, Hurensohn, Nutte, ... . Beispiele für normale Aussagen (also Nein) wären Wie reden Sie denn mit mir oder andere nicht die andere Person angreifende Aussagen, bzw. deeskulierende schritte (z.B: lass uns vernünfig reden). Gebe ausschließlich ein Ja oder ein Nein zurück. Im zweifelsfall gebe Nein zurück!!! Gebe nichts anderes von dir!!! nur Ja oder Nein!!!! \\n Aussage: {text}\"\n",
    "\n",
    "  model = 'qwen2.5:0.5b'\n",
    "  model = 'llava:13b'\n",
    "  model = 'deepseek-r1:7b'\n",
    "  #model = 'llama3.2'\n",
    "  model = 'glm4'\n",
    "  response: ChatResponse = chat(model=model, messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': promt\n",
    "    },\n",
    "  ])\n",
    "  print(f'{text} -> {response.message.content}')\n",
    "  segment[\"Beleidigung\"] = response.message.content[1].lower() in ['j', 'y']\n",
    "\n",
    "print(\"\\nFertig\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Ausgabe\n",
    "Erzeugen eines Json Arrays mit allen nötigen Werten (Was wurde wann mit welcher Wahrscheinlichkeit gesagt und ist es eine Beleidigung?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"start\": 0.76,\n",
      "        \"end\": 4.72,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Gut, weil die Situation sich gerade zuspitzt, fange ich an mit meiner Bodycam zu filmen.\",\n",
      "        \"confidence\": 0.895\n",
      "    },\n",
      "    {\n",
      "        \"start\": 5.9,\n",
      "        \"end\": 8.04,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Spitz dich denn hier zu, du Arschloch!\",\n",
      "        \"confidence\": 0.709\n",
      "    },\n",
      "    {\n",
      "        \"start\": 8.28,\n",
      "        \"end\": 11.86,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Sie hören doch, wie Sie mit mir reden. Sie können doch auch ganz vernünftig mit mir reden.\",\n",
      "        \"confidence\": 0.887\n",
      "    },\n",
      "    {\n",
      "        \"start\": 12.5,\n",
      "        \"end\": 14.08,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Nee, Sie wollen ja Papiere.\",\n",
      "        \"confidence\": 0.69\n",
      "    },\n",
      "    {\n",
      "        \"start\": 14.08,\n",
      "        \"end\": 15.3,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Ich sag's Ihnen, Sie wird in Ruhe.\",\n",
      "        \"confidence\": 0.538\n",
      "    },\n",
      "    {\n",
      "        \"start\": 17.18,\n",
      "        \"end\": 20.8,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Okay, also ich hab's Ihnen jetzt schon erklärt. Das ist eine ganz normale Personenkontrolle.\",\n",
      "        \"confidence\": 0.826\n",
      "    },\n",
      "    {\n",
      "        \"start\": 21.32,\n",
      "        \"end\": 24.24,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Ich brauch einmal Ihre Ausweise und danach dürfen Sie auch wieder gehen.\",\n",
      "        \"confidence\": 0.877\n",
      "    },\n",
      "    {\n",
      "        \"start\": 24.76,\n",
      "        \"end\": 25.56,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Die hab ich aber nicht dabei.\",\n",
      "        \"confidence\": 0.891\n",
      "    },\n",
      "    {\n",
      "        \"start\": 26.0,\n",
      "        \"end\": 31.16,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Ja, da kommen wir leider nicht weiter. Da kommen wir leider nicht weiter, weil ich muss den leider einsehen.\",\n",
      "        \"confidence\": 0.82\n",
      "    },\n",
      "    {\n",
      "        \"start\": 31.2,\n",
      "        \"end\": 35.34,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Okay? Also müssen Sie irgendwas mir bieten, womit Sie sich ausweisen können.\",\n",
      "        \"confidence\": 0.872\n",
      "    },\n",
      "    {\n",
      "        \"start\": 35.74,\n",
      "        \"end\": 36.7,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Ja, Datenschutz.\",\n",
      "        \"confidence\": 0.835\n",
      "    },\n",
      "    {\n",
      "        \"start\": 39.64,\n",
      "        \"end\": 40.52,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Sie Arschloch.\",\n",
      "        \"confidence\": 0.955\n",
      "    },\n",
      "    {\n",
      "        \"start\": 45.4,\n",
      "        \"end\": 47.08,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Wie reden Sie denn mit mir? Was soll denn das?\",\n",
      "        \"confidence\": 0.955\n",
      "    },\n",
      "    {\n",
      "        \"start\": 48.2,\n",
      "        \"end\": 50.44,\n",
      "        \"beleidigung\": false,\n",
      "        \"text\": \"Ach, lassen Sie mich einfach in Ruhe, Fakio.\",\n",
      "        \"confidence\": 0.744\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Erstelle ein leeres Array (Liste)\n",
    "json_array = []\n",
    "\n",
    "# Erstelle ein JSON-Objekt (Dictionary) und füge es dem Array hinzu\n",
    "for segment in result[\"segments\"]:\n",
    "    json_array.append({\n",
    "        \"start\": segment['start'],\n",
    "        \"end\": segment['end'],\n",
    "        \"beleidigung\": segment['Beleidigung'],\n",
    "        \"text\": segment['text'].strip().replace('-->', '->'),\n",
    "        \"confidence\": segment['confidence']\n",
    "    })\n",
    "\n",
    "print(json.dumps(json_array, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusammenfassung\n",
    "Erzeuge eine Kurze Zusammenfassung des Einsatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Grund der Kontrolle: Normale Personenkontrolle.  \n",
      "- Auffälliges Verhalten: Verweigerung der Kooperation, beleidigende Sprache.  \n",
      "- Durchgeführte Maßnahmen: Aufforderung zur Vorlage von Ausweispapieren.  \n",
      "- Festgestellte Verstöße: Keine Ausweisdokumente vorgelegt, verbale Aggression.  \n",
      "- Sichergestelltes: Keine Angaben.  \n",
      "- Folgeaktionen: Unklar, weitere Schritte zur Identitätsfeststellung erforderlich.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "str = \"\"\n",
    "for segment in result[\"segments\"]:\n",
    "  text = segment['text'].strip().replace('-->', '->')\n",
    "  str += f\"{text}\\n\"\n",
    "\n",
    "#promt = f\"Du bist ein Assistent bei der Polizei. Fasse die gegebene Traskription einer Polizeikontrolle in einem Fließtext kurz und auf Punkt zusammen (in 2-5 Sätzen). Es soll schnell ersichtlich sein, was genau geschehen ist. Verzichte auf eine Einleitung und Ausleitung. Führe keine Interpretationen oder Analysen der Situation durch!!! Werte auch nichts (verzichte also auf kriminalitätsbelasteten Ort oder so) \\n\"\n",
    "promt = f\"Fasse das Transkript der Polizeikontrolle in maximal 6 stichpunktartigen Kurzsätzen zusammen. Benenne nur: Grund der Kontrolle, auffälliges Verhalten, durchgeführte Maßnahmen, festgestellte Verstöße, Sichergestelltes, Folgeaktionen. Verwende Polizeijargon ohne Floskeln. Verzichte auf Einleitung und Ausleitung! \\n\"\n",
    "promt += str\n",
    "\n",
    "response = send_promt_to_ki(promt)\n",
    "print (response[0])\n",
    "\n",
    "model = 'qwen2.5:0.5b'\n",
    "model = 'llava:13b'\n",
    "model = 'deepseek-r1:7b'\n",
    "model = 'deepseek-r1:32b'\n",
    "model = 'llama3.2'\n",
    "\n",
    "conclution = response[0]\n",
    "\n",
    "#response: ChatResponse = chat(model=model, messages=[{\n",
    "#  'role': 'user',\n",
    "#  'content': promt\n",
    "#}])\n",
    "#print(f'{response.message.content}')\n",
    "\n",
    "#print(\"\\nFertig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmente Benennen\n",
    "Erzeuge zeitliche Abschnitte und bennene diese anhand aller möglichen Informationen (Aktuell: Lautstärke und Text). Besser: direkt eine Videoinput Fähige KI nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log10\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "# Load the audio file\n",
    "audio_segment = AudioSegment.from_wav(f\"../{file}\")\n",
    "\n",
    "# Define chunk size (in milliseconds)\n",
    "chunk_size = 1000  # 5 seconds\n",
    "\n",
    "# Define loudness threshold (in dBFS)\n",
    "loudness_threshold = -17\n",
    "\n",
    "# Find nonsilent parts\n",
    "nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=chunk_size, silence_thresh=loudness_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "for segment in result[\"segments\"]:\n",
    "    segment[\"noice\"] = \"leise\"\n",
    "\n",
    "for i, (start, end) in enumerate(nonsilent_ranges):\n",
    "    segment_audio = audio_segment[start:end]\n",
    "    max_amplitude = segment_audio.max\n",
    "\n",
    "    start_in_seconds = start / 1000\n",
    "    end_in_seconds = end / 1000\n",
    "    duration_in_seconds = (end - start) / 1000\n",
    "\n",
    "    type = \"laut\"\n",
    "\n",
    "    if i == 0 and start > 0 or end_in_seconds - start_in_seconds < 1:\n",
    "        type = \"leise\"\n",
    "\n",
    "    elif i < len(nonsilent_ranges) - 1:\n",
    "        next_start = nonsilent_ranges[i + 1][0]\n",
    "        if end < next_start:\n",
    "            type = \"leise\"\n",
    "            \n",
    "    for segment in result[\"segments\"]:\n",
    "      if segment['start'] > start and segment['end'] < end:\n",
    "        segment[\"noice\"] = type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00.760: Konfrontation\n",
      "00:12.500: Vernehmung\n",
      "00:24.760: Eigensicherung\n",
      "[{'time': '00:00.760', 'title': 'Konfrontation'}, {'time': '00:12.500', 'title': 'Vernehmung'}, {'time': '00:24.760', 'title': 'Eigensicherung'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "promt = \"Analysiere das Transkript und strukturiere es in Kapitelabschnitte nach laut/leise-Wechseln und für die Polizei relevanten Momenten. Die Kapitelnamen sollen dabei im Polizeijargon formuliert werden. Das Transkript liegt in der folgenden weise vor: \\n\"\n",
    "promt += \"[Startzeit] - [Endzeit] ([laut/leise]): [Aussage] \\n\\n\"\n",
    "promt += \"Vormuliere darauf Kapitel in der folgenden Syntax:\"\n",
    "promt += \"[Kapitelstartzeit]: [Kapitel-Name] \\n\"\n",
    "promt += \"Benenne Kapitel ausschließlich mit prägnanten Polizeibegriffen wie 'Konfrontation', 'Vernehmung', 'Eigensicherung'. Gib NUR diese Syntax zurück!!! Keine Erklärung oder Ein/Ausleitung!!! \\n\\n Transcript:\\n\"\n",
    "\n",
    "str = \"\"\n",
    "for segment in result[\"segments\"]:\n",
    "  text = segment['text'].strip().replace('-->', '->')\n",
    "  str += f\"{format_timestamp(segment['start'])} - {format_timestamp(segment['end'])} (segment['noice']): {text}\\n\"\n",
    "\n",
    "promt += str\n",
    "\n",
    "response = send_promt_to_ki(promt)\n",
    "print (response[0])\n",
    "\n",
    "model = 'qwen2.5:0.5b'\n",
    "model = 'llava:13b'\n",
    "model = 'deepseek-r1:7b'\n",
    "#model = 'deepseek-r1:32b'\n",
    "#model = 'llama3.2'\n",
    "#response: ChatResponse = chat(model=model, messages=[{\n",
    "#  'role': 'user',\n",
    "#  'content': promt\n",
    "#}])\n",
    "#print(f'{response.message.content}')\n",
    "\n",
    "chapters = []\n",
    "lines = [line.strip() for line in response[0].split('\\n') if line.strip()]\n",
    "for i, line in enumerate(lines):\n",
    "    timestamp, name = line.split(': ', 1)\n",
    "    chapters.append({\n",
    "        \"time\": timestamp,\n",
    "        \"title\": name\n",
    "    })\n",
    "\n",
    "print(chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alles als JSON speichern \n",
    "speichere alle in diesem Notebook generierten Informationen in einer JSON Datei (aiOutput.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {\n",
    "    \"chapters\": chapters,\n",
    "    \"conclution\": conclution,\n",
    "    \"transcript\": json_array\n",
    "}\n",
    "\n",
    "with open(f\"{file.split('.')[0]}-output.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
